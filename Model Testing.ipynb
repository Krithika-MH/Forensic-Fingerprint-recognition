{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3365374-3af2-411b-9589-add27f969840",
   "metadata": {},
   "outputs": [],
   "source": [
    "#om gan ganapathaye namah om namah shivaya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18a4ade3-03f6-4e94-a11d-4677645cf0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index map built for 55270 aggregated feature files.\n",
      "\n",
      "=== Elastic matching on VAL set ===\n",
      "pairs_val.csv: sampled 50000/641121 pairs for elastic evaluation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pairs_val.csv: 100%|██████████████████████████████████████████████| 50000/50000 [46:55<00:00, 17.76 pairs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished pairs_val.csv elastic scoring. Pairs: 50000; labels: 50000\n",
      "\n",
      "=== Elastic matching on TEST set ===\n",
      "pairs_test.csv: sampled 50000/665673 pairs for elastic evaluation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pairs_test.csv: 100%|█████████████████████████████████████████████| 50000/50000 [54:54<00:00, 15.18 pairs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished pairs_test.csv elastic scoring. Pairs: 50000; labels: 50000\n",
      "\n",
      "=== Calibrating ELASTIC-ONLY threshold on VAL ===\n",
      "elastic_val score range: [0.0013, 1.0000]\n",
      "ELASTIC_VAL best_thr=0.0214, acc=0.7812, TPR=0.5655, FPR=0.0368\n",
      "\n",
      "=== Evaluating ELASTIC-ONLY on TEST at VAL threshold ===\n",
      "ELASTIC TEST @thr=0.0214 -> acc=0.7803, TPR=0.5556, FPR=0.0316\n",
      "\n",
      "=== Loading SNN distances for fusion ===\n",
      "\n",
      "=== Calibrating FUSION threshold on VAL ===\n",
      "fusion_val score range: [0.1760, 1.0000]\n",
      "FUSION_VAL best_thr=0.3334, acc=0.8397, TPR=0.8113, FPR=0.1364\n",
      "\n",
      "=== Evaluating FUSION on TEST at VAL threshold ===\n",
      "FUSION TEST @thr=0.3334 -> acc=0.8379, TPR=0.8026, FPR=0.1325\n",
      "\n",
      "Saved elastic and fusion scores to D:\\5th sem\\mini_project\\models\\elastic_fusion_scores.npz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm # Library for progress bars (must be installed: pip install tqdm)\n",
    "\n",
    "# ========= CONFIG (50k Limits Confirmed) =========\n",
    "INDEX_CSV    = r\"D:\\5th sem\\mini_project\\dataset\\socofing_index_features.csv\"\n",
    "PAIRS_VAL    = r\"D:\\5th sem\\mini_project\\dataset\\pairs\\pairs_val.csv\"\n",
    "PAIRS_TEST   = r\"D:\\5th sem\\mini_project\\dataset\\pairs\\pairs_test.csv\"\n",
    "\n",
    "# From previous SNN evaluation step\n",
    "SNN_NPZ      = r\"D:\\5th sem\\mini_project\\models\\snn_eval_distances.npz\"\n",
    "\n",
    "# VITAL: Limits set to 50k for fast CPU run\n",
    "MAX_VAL_PAIRS  = 50000 \n",
    "MAX_TEST_PAIRS = 50000 \n",
    "\n",
    "RATIO_THRESH = 0.75\n",
    "RANDOM_SEED  = 42\n",
    "\n",
    "\n",
    "# ========= STEP 1: BUILD agg_path -> des_path MAP =========\n",
    "def build_agg_to_des_map(index_csv):\n",
    "    df_idx = pd.read_csv(index_csv)\n",
    "    assert \"agg_path\" in df_idx.columns and \"des_path\" in df_idx.columns, \\\n",
    "        \"Index CSV must have agg_path and des_path columns\"\n",
    "    mapping = dict(zip(df_idx[\"agg_path\"], df_idx[\"des_path\"]))\n",
    "    print(f\"Index map built for {len(mapping)} aggregated feature files.\")\n",
    "    return mapping\n",
    "\n",
    "\n",
    "# ========= STEP 2: ELASTIC SCORE (SIFT + BF + RATIO TEST) =========\n",
    "def compute_elastic_score(des1, des2, ratio_thresh=0.75):\n",
    "    \"\"\"\n",
    "    des1, des2: numpy arrays [N1, 128], [N2, 128] (float32)\n",
    "    Returns normalized elastic score in [0,1].\n",
    "    \"\"\"\n",
    "    if des1 is None or des2 is None or len(des1) < 2 or len(des2) < 2:\n",
    "        return 0.0\n",
    "\n",
    "    des1 = des1.astype(np.float32)\n",
    "    des2 = des2.astype(np.float32)\n",
    "\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < ratio_thresh * n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    good_count = len(good)\n",
    "    denom = max(len(des1), len(des2))\n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return good_count / float(denom)\n",
    "\n",
    "\n",
    "# ========= STEP 3: COMPUTE ELASTIC SCORES FOR A PAIR CSV (FIXED) =========\n",
    "def compute_elastic_for_pairs(pairs_csv, agg_to_des_map, max_pairs=None):\n",
    "    df_pairs = pd.read_csv(pairs_csv)\n",
    "    n_total = len(df_pairs)\n",
    "    csv_name = os.path.basename(pairs_csv)\n",
    "\n",
    "    if max_pairs is not None and max_pairs < n_total:\n",
    "        # FIX: Sample the DataFrame, but DO NOT call .reset_index(drop=True).\n",
    "        # This ensures the sampled DataFrame retains the ORIGINAL row indices.\n",
    "        df_pairs = df_pairs.sample(n=max_pairs, random_state=RANDOM_SEED)\n",
    "        print(f\"{csv_name}: sampled {len(df_pairs)}/{n_total} pairs for elastic evaluation.\")\n",
    "    else:\n",
    "        print(f\"{csv_name}: using all {n_total} pairs for elastic evaluation.\")\n",
    "\n",
    "    # idxs_out now correctly holds the ORIGINAL row indices from the full CSV, \n",
    "    # which is necessary for indexing into the SNN NPZ file.\n",
    "    idxs_out = df_pairs.index.to_numpy(dtype=np.int64) \n",
    "    \n",
    "    labels = df_pairs[\"label\"].to_numpy(dtype=np.float32)\n",
    "\n",
    "    des_cache = {}\n",
    "    scores = []\n",
    "    \n",
    "    # Initialize the progress bar using tqdm\n",
    "    tqdm_iter = tqdm(df_pairs.iterrows(), \n",
    "                     total=len(df_pairs), \n",
    "                     desc=f\"Processing {csv_name}\",\n",
    "                     unit=\" pairs\")\n",
    "\n",
    "    for idx, row in tqdm_iter:\n",
    "        agg1 = row[\"agg_path_1\"]\n",
    "        agg2 = row[\"agg_path_2\"]\n",
    "\n",
    "        des_path_1 = agg_to_des_map.get(agg1, None)\n",
    "        des_path_2 = agg_to_des_map.get(agg2, None)\n",
    "\n",
    "        if des_path_1 is None or des_path_2 is None:\n",
    "            scores.append(0.0)\n",
    "            continue\n",
    "\n",
    "        # Load descriptors with caching\n",
    "        if des_path_1 not in des_cache:\n",
    "            if os.path.exists(des_path_1):\n",
    "                des_cache[des_path_1] = np.load(des_path_1)\n",
    "            else:\n",
    "                des_cache[des_path_1] = None\n",
    "\n",
    "        if des_path_2 not in des_cache:\n",
    "            if os.path.exists(des_path_2):\n",
    "                des_cache[des_path_2] = np.load(des_path_2)\n",
    "            else:\n",
    "                des_cache[des_path_2] = None\n",
    "\n",
    "        des1 = des_cache[des_path_1]\n",
    "        des2 = des_cache[des_path_2]\n",
    "\n",
    "        score = compute_elastic_score(des1, des2, ratio_thresh=RATIO_THRESH)\n",
    "        scores.append(score)\n",
    "\n",
    "    scores = np.array(scores, dtype=np.float32)\n",
    "    print(f\"\\nFinished {csv_name} elastic scoring. Pairs: {len(scores)}; labels: {len(labels)}\")\n",
    "    \n",
    "    # Return the correct original indices for fusion\n",
    "    return scores, labels, idxs_out\n",
    "\n",
    "\n",
    "# ========= STEP 4: CALIBRATE THRESHOLD (ELASTIC ONLY) (Unchanged) =========\n",
    "def calibrate_threshold(scores, labels, mode=\"elastic\"):\n",
    "    s_min, s_max = float(scores.min()), float(scores.max())\n",
    "    print(f\"{mode} score range: [{s_min:.4f}, {s_max:.4f}]\")\n",
    "\n",
    "    best_acc = 0.0\n",
    "    best_thr = None\n",
    "\n",
    "    thresholds = np.linspace(s_min, s_max, num=200)\n",
    "\n",
    "    for thr in thresholds:\n",
    "        preds = (scores >= thr).astype(np.float32)\n",
    "        correct = (preds == labels).sum()\n",
    "        acc = correct / len(labels)\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_thr = thr\n",
    "\n",
    "    pos_mask = (labels == 1)\n",
    "    neg_mask = (labels == 0)\n",
    "\n",
    "    tpr = ((scores[pos_mask] >= best_thr).sum() / pos_mask.sum())\n",
    "    fpr = ((scores[neg_mask] >= best_thr).sum() / neg_mask.sum())\n",
    "\n",
    "    print(f\"{mode.upper()} best_thr={best_thr:.4f}, acc={best_acc:.4f}, \"\n",
    "          f\"TPR={tpr:.4f}, FPR={fpr:.4f}\")\n",
    "    return best_thr, best_acc, tpr, fpr\n",
    "\n",
    "\n",
    "# ========= STEP 5: MAIN PIPELINE (Unchanged except for the necessary fixes) =========\n",
    "def main():\n",
    "    # --- mapping agg_path -> des_path ---\n",
    "    agg_to_des = build_agg_to_des_map(INDEX_CSV)\n",
    "\n",
    "    # --- elastic scores on VAL and TEST ---\n",
    "    print(\"\\n=== Elastic matching on VAL set ===\")\n",
    "    elastic_val, labels_val, idxs_val = compute_elastic_for_pairs(\n",
    "        PAIRS_VAL, agg_to_des, max_pairs=MAX_VAL_PAIRS\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== Elastic matching on TEST set ===\")\n",
    "    elastic_test, labels_test, idxs_test = compute_elastic_for_pairs(\n",
    "        PAIRS_TEST, agg_to_des, max_pairs=MAX_TEST_PAIRS\n",
    "    )\n",
    "\n",
    "    # --- calibrate elastic-only threshold on VAL ---\n",
    "    print(\"\\n=== Calibrating ELASTIC-ONLY threshold on VAL ===\")\n",
    "    best_thr_el, best_acc_el, tpr_el, fpr_el = calibrate_threshold(elastic_val, labels_val, mode=\"elastic_val\")\n",
    "\n",
    "    print(\"\\n=== Evaluating ELASTIC-ONLY on TEST at VAL threshold ===\")\n",
    "    preds_test_el = (elastic_test >= best_thr_el).astype(np.float32)\n",
    "    correct_test_el = (preds_test_el == labels_test).sum()\n",
    "    acc_test_el = correct_test_el / len(labels_test)\n",
    "\n",
    "    pos_mask_t = (labels_test == 1)\n",
    "    neg_mask_t = (labels_test == 0)\n",
    "\n",
    "    tpr_t_el = ((elastic_test[pos_mask_t] >= best_thr_el).sum() / pos_mask_t.sum())\n",
    "    fpr_t_el = ((elastic_test[neg_mask_t] >= best_thr_el).sum() / neg_mask_t.sum())\n",
    "\n",
    "    print(f\"ELASTIC TEST @thr={best_thr_el:.4f} -> \"\n",
    "          f\"acc={acc_test_el:.4f}, TPR={tpr_t_el:.4f}, FPR={fpr_t_el:.4f}\")\n",
    "\n",
    "    # --- Load SNN distances for fusion ---\n",
    "    print(\"\\n=== Loading SNN distances for fusion ===\")\n",
    "    snn_data = np.load(SNN_NPZ)\n",
    "    val_dist_all   = snn_data[\"val_dist\"]\n",
    "    val_labels_all = snn_data[\"val_labels\"]\n",
    "    test_dist_all  = snn_data[\"test_dist\"]\n",
    "    test_labels_all= snn_data[\"test_labels\"]\n",
    "\n",
    "    # SANITY CHECK: This assertion should now PASS because idxs_val/idxs_test \n",
    "    # contain the correct original row indices.\n",
    "    assert np.allclose(labels_val,    val_labels_all[idxs_val]),  \"VAL labels mismatch between CSV and SNN npz\"\n",
    "    assert np.allclose(labels_test,  test_labels_all[idxs_test]),\"TEST labels mismatch between CSV and SNN npz\"\n",
    "\n",
    "    # convert SNN distances to similarity in [0,1]\n",
    "    snn_sim_val  = 1.0 / (1.0 + val_dist_all[idxs_val])\n",
    "    snn_sim_test = 1.0 / (1.0 + test_dist_all[idxs_test])\n",
    "\n",
    "    # simple fusion: average of SNN similarity and elastic score\n",
    "    fusion_val  = 0.5 * snn_sim_val  + 0.5 * elastic_val\n",
    "    fusion_test = 0.5 * snn_sim_test + 0.5 * elastic_test\n",
    "\n",
    "    print(\"\\n=== Calibrating FUSION threshold on VAL ===\")\n",
    "    best_thr_fus, best_acc_fus, tpr_fus, fpr_fus = calibrate_threshold(fusion_val, labels_val, mode=\"fusion_val\")\n",
    "\n",
    "    print(\"\\n=== Evaluating FUSION on TEST at VAL threshold ===\")\n",
    "    preds_test_fus = (fusion_test >= best_thr_fus).astype(np.float32)\n",
    "    correct_test_fus = (preds_test_fus == labels_test).sum()\n",
    "    acc_test_fus = correct_test_fus / len(labels_test)\n",
    "\n",
    "    pos_mask_t = (labels_test == 1)\n",
    "    neg_mask_t = (labels_test == 0)\n",
    "\n",
    "    tpr_t_fus = ((fusion_test[pos_mask_t] >= best_thr_fus).sum() / pos_mask_t.sum())\n",
    "    fpr_t_fus = ((fusion_test[neg_mask_t] >= best_thr_fus).sum() / neg_mask_t.sum())\n",
    "\n",
    "    print(f\"FUSION TEST @thr={best_thr_fus:.4f} -> \"\n",
    "          f\"acc={acc_test_fus:.4f}, TPR={tpr_t_fus:.4f}, FPR={fpr_t_fus:.4f}\")\n",
    "\n",
    "    # --- save scores for later analysis ---\n",
    "    OUT_NPZ = r\"D:\\5th sem\\mini_project\\models\\elastic_fusion_scores.npz\"\n",
    "    np.savez(\n",
    "        OUT_NPZ,\n",
    "        elastic_val=elastic_val,\n",
    "        labels_val=labels_val,\n",
    "        elastic_test=elastic_test,\n",
    "        labels_test=labels_test,\n",
    "        fusion_val=fusion_val,\n",
    "        fusion_test=fusion_test,\n",
    "        idxs_val=idxs_val,\n",
    "        idxs_test=idxs_test,\n",
    "        best_thr_el=best_thr_el,\n",
    "        best_thr_fus=best_thr_fus,\n",
    "    )\n",
    "    print(f\"\\nSaved elastic and fusion scores to {OUT_NPZ}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc69f8ba-d99d-446f-bc39-eb25a5cb6d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Gallery size: 12000 (real fingerprints)\n",
      "Probes size:  200 (altered=hard)\n",
      "Loaded SNN embedding model from D:\\5th sem\\mini_project\\models\\snn_sift_agg_best.pt\n",
      "Gallery embeddings shape: torch.Size([12000, 128])\n",
      "\n",
      "=== 1:N Identification Evaluation ===\n",
      "Processed 50/200 probes...\n",
      "Processed 100/200 probes...\n",
      "Processed 150/200 probes...\n",
      "Processed 200/200 probes...\n",
      "Rank-1 identification rate: 0.6600  (132/200)\n",
      "Rank-5 identification rate: 0.6650  (133/200)\n",
      "Rank-10 identification rate: 0.6650  (133/200)\n",
      "Rank-20 identification rate: 0.6700  (134/200)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "\n",
    "# ========== CONFIG ==========\n",
    "INDEX_CSV = r\"D:\\5th sem\\mini_project\\dataset\\socofing_index_features.csv\"\n",
    "MODEL_PATH = r\"D:\\5th sem\\mini_project\\models\\snn_sift_agg_best.pt\"\n",
    "\n",
    "# Where full descriptors are already saved (used via des_path in CSV)\n",
    "# e.g., D:\\5th sem\\mini_project\\dataset\\NPYSF_full_des\\...\n",
    "\n",
    "# 1:N evaluation settings\n",
    "# 1:N evaluation settings\n",
    "ALTER_LEVEL_PROBE = \"hard\"     # keep as hard for forensic difficulty\n",
    "MAX_PROBES = 200               # start with 200 probes to run fast\n",
    "TOP_K1 = 100                   # refine top 100 candidates per probe\n",
    "TOP_RANKS = [1, 5, 10, 20]     # metrics you care about\n",
    "RATIO_THRESH = 0.75            # keep this\n",
    "SNN_WEIGHT  = 0.5\n",
    "EL_WEIGHT   = 0.5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "# ========== MODEL (same as training) ==========\n",
    "class SiameseBranch(nn.Module):\n",
    "    def __init__(self, input_dim=128, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, embedding_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class SiameseNetworkEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Single-branch version: take one 128-D vector and output embedding.\n",
    "    We reuse the same branch as in the Siamese model.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=128, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        self.branch = SiameseBranch(input_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.branch(x)\n",
    "\n",
    "\n",
    "# ========== ELASTIC MATCHING (SIFT descriptor-based) ==========\n",
    "def compute_elastic_score(des1, des2, ratio_thresh=0.75):\n",
    "    \"\"\"\n",
    "    des1, des2: numpy arrays [N1, 128], [N2, 128] (float32)\n",
    "    Returns normalized elastic score in [0,1].\n",
    "    \"\"\"\n",
    "    if des1 is None or des2 is None or len(des1) < 2 or len(des2) < 2:\n",
    "        return 0.0\n",
    "\n",
    "    des1 = des1.astype(np.float32)\n",
    "    des2 = des2.astype(np.float32)\n",
    "\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < ratio_thresh * n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    good_count = len(good)\n",
    "    denom = max(len(des1), len(des2))\n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return good_count / float(denom)\n",
    "\n",
    "\n",
    "# ========== LOAD DATA (GALLERY & PROBES) ==========\n",
    "def load_index_and_split(index_csv, alter_level_probe=\"hard\", max_probes=None):\n",
    "    df = pd.read_csv(index_csv)\n",
    "\n",
    "    # Gallery: all real (unaltered) fingerprints\n",
    "    gallery_df = df[df[\"real_or_altered\"].str.lower() == \"real\"].copy()\n",
    "\n",
    "    # Probes: altered with requested level\n",
    "    if alter_level_probe == \"all\":\n",
    "        probes_df = df[df[\"real_or_altered\"].str.lower() == \"altered\"].copy()\n",
    "    else:\n",
    "        probes_df = df[\n",
    "            (df[\"real_or_altered\"].str.lower() == \"altered\") &\n",
    "            (df[\"alter_level\"].str.lower() == alter_level_probe.lower())\n",
    "        ].copy()\n",
    "\n",
    "    if max_probes is not None and max_probes < len(probes_df):\n",
    "        probes_df = probes_df.sample(n=max_probes, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    print(f\"Gallery size: {len(gallery_df)} (real fingerprints)\")\n",
    "    print(f\"Probes size:  {len(probes_df)} (altered={alter_level_probe})\")\n",
    "\n",
    "    return gallery_df.reset_index(drop=True), probes_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# ========== PRECOMPUTE SNN EMBEDDINGS FOR GALLERY ==========\n",
    "def compute_gallery_embeddings(model, gallery_df):\n",
    "    \"\"\"\n",
    "    Loads all agg vectors for gallery, computes embeddings.\n",
    "    Returns:\n",
    "      gallery_feats: [N_gallery, 128] tensor\n",
    "      gallery_embs:  [N_gallery, emb_dim] tensor\n",
    "    \"\"\"\n",
    "    agg_paths = gallery_df[\"agg_path\"].tolist()\n",
    "    feats = []\n",
    "    for p in agg_paths:\n",
    "        v = np.load(p).astype(np.float32)  # [128]\n",
    "        feats.append(v)\n",
    "\n",
    "    feats = np.stack(feats, axis=0)  # [N_gallery, 128]\n",
    "    feats_t = torch.from_numpy(feats).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        embs = model(feats_t)  # [N_gallery, emb_dim]\n",
    "\n",
    "    print(f\"Gallery embeddings shape: {embs.shape}\")\n",
    "    return feats_t.cpu(), embs.cpu()\n",
    "\n",
    "\n",
    "# ========== LOAD DESCRIPTORS INTO CACHE FOR GALLERY ==========\n",
    "def build_gallery_descriptor_cache(gallery_df):\n",
    "    \"\"\"\n",
    "    Prepares a dict index -> descriptors for gallery.\n",
    "    Each entry is loaded on first use (lazy caching).\n",
    "    \"\"\"\n",
    "    des_paths = gallery_df[\"des_path\"].tolist()\n",
    "    cache = {}\n",
    "    return des_paths, cache\n",
    "\n",
    "\n",
    "# ========== 1:N MATCHING FOR A SINGLE PROBE ==========\n",
    "def identify_probe(\n",
    "    probe_row,\n",
    "    gallery_df,\n",
    "    gallery_embs,\n",
    "    snn_model,\n",
    "    des_paths_gallery,\n",
    "    des_cache,\n",
    "    top_k1=200,\n",
    "    ratio_thresh=0.75,\n",
    "    snn_weight=0.5,\n",
    "    el_weight=0.5\n",
    "):\n",
    "    \"\"\"\n",
    "    For a single probe fingerprint:\n",
    "      - compute its embedding\n",
    "      - compute SNN distances to all gallery\n",
    "      - select TOP_K1 by SNN similarity\n",
    "      - for those, compute elastic_score\n",
    "      - fuse SNN similarity and elastic_score\n",
    "      - return sorted candidate indices and fused scores\n",
    "    \"\"\"\n",
    "    # --- SNN embedding of probe ---\n",
    "    v_probe = np.load(probe_row[\"agg_path\"]).astype(np.float32)  # [128]\n",
    "    v_probe_t = torch.from_numpy(v_probe).unsqueeze(0).to(device)  # [1,128]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        z_probe = snn_model(v_probe_t)  # [1,emb_dim]\n",
    "    z_probe = z_probe.cpu()  # [1,emb_dim]\n",
    "\n",
    "    # --- SNN distances to gallery (vectorized) ---\n",
    "    # gallery_embs: [N_gallery, emb_dim]\n",
    "    diff = gallery_embs - z_probe  # [N_gallery, emb_dim]\n",
    "    dists = torch.norm(diff, dim=1).numpy()  # [N_gallery]\n",
    "\n",
    "    # convert to similarity in [0,1]: s = 1/(1+d)\n",
    "    snn_sim = 1.0 / (1.0 + dists)  # [N_gallery]\n",
    "\n",
    "    # --- top-K1 candidates by SNN similarity ---\n",
    "    N_gallery = len(gallery_df)\n",
    "    k1 = min(top_k1, N_gallery)\n",
    "    # argsort descending by similarity\n",
    "    idx_sorted_snn = np.argsort(-snn_sim)  # high to low\n",
    "    cand_idx = idx_sorted_snn[:k1]\n",
    "\n",
    "    # --- elastic matching for those K1 candidates ---\n",
    "    elastic_scores = np.zeros(k1, dtype=np.float32)\n",
    "\n",
    "    # Load probe descriptors\n",
    "    des_path_probe = probe_row[\"des_path\"]\n",
    "    if os.path.exists(des_path_probe):\n",
    "        des_probe = np.load(des_path_probe).astype(np.float32)\n",
    "    else:\n",
    "        des_probe = None\n",
    "\n",
    "    for i, g_idx in enumerate(cand_idx):\n",
    "        des_path_g = des_paths_gallery[g_idx]\n",
    "\n",
    "        if des_path_g not in des_cache:\n",
    "            if os.path.exists(des_path_g):\n",
    "                des_cache[des_path_g] = np.load(des_path_g).astype(np.float32)\n",
    "            else:\n",
    "                des_cache[des_path_g] = None\n",
    "\n",
    "        des_g = des_cache[des_path_g]\n",
    "\n",
    "        elastic_scores[i] = compute_elastic_score(des_probe, des_g, ratio_thresh=ratio_thresh)\n",
    "\n",
    "    # --- fuse scores ---\n",
    "    snn_sim_top = snn_sim[cand_idx]  # [K1]\n",
    "\n",
    "    # optional: normalize elastic scores to [0,1] (already approximately [0,1])\n",
    "    # fusion: weighted average\n",
    "    fused_scores = snn_weight * snn_sim_top + el_weight * elastic_scores\n",
    "\n",
    "    # sort candidates by fused_scores descending\n",
    "    order = np.argsort(-fused_scores)\n",
    "    final_idx = cand_idx[order]\n",
    "    final_scores = fused_scores[order]\n",
    "\n",
    "    return final_idx, final_scores\n",
    "\n",
    "\n",
    "# ========== 1:N EVALUATION ==========\n",
    "def evaluate_identification(\n",
    "    gallery_df,\n",
    "    probes_df,\n",
    "    gallery_embs,\n",
    "    snn_model,\n",
    "    des_paths_gallery,\n",
    "    des_cache,\n",
    "    top_k1=200,\n",
    "    top_ranks=(1, 5, 10, 20),\n",
    "    ratio_thresh=0.75,\n",
    "    snn_weight=0.5,\n",
    "    el_weight=0.5\n",
    "):\n",
    "    \"\"\"\n",
    "    For each probe, perform 1:N identification and measure\n",
    "    rank-1, rank-5, rank-10, etc. identification rates.\n",
    "    \"\"\"\n",
    "    total = len(probes_df)\n",
    "    rank_hits = {k: 0 for k in top_ranks}\n",
    "\n",
    "    for idx_probe, probe_row in probes_df.iterrows():\n",
    "        true_subj = probe_row[\"subject_id\"]\n",
    "\n",
    "        # get ranking of gallery indices by fused score\n",
    "        cand_indices, fused_scores = identify_probe(\n",
    "            probe_row,\n",
    "            gallery_df,\n",
    "            gallery_embs,\n",
    "            snn_model,\n",
    "            des_paths_gallery,\n",
    "            des_cache,\n",
    "            top_k1=top_k1,\n",
    "            ratio_thresh=ratio_thresh,\n",
    "            snn_weight=snn_weight,\n",
    "            el_weight=el_weight\n",
    "        )\n",
    "\n",
    "        # convert gallery indices to subject IDs\n",
    "        subj_candidates = gallery_df.loc[cand_indices, \"subject_id\"].to_numpy()\n",
    "\n",
    "        # find the first occurrence (rank) of true_subj in subj_candidates\n",
    "        ranks = np.where(subj_candidates == true_subj)[0]\n",
    "        if len(ranks) > 0:\n",
    "            r = int(ranks[0]) + 1  # rank position (1-based)\n",
    "        else:\n",
    "            r = None  # not found in top-K1\n",
    "\n",
    "        # update hit counts for each top_k\n",
    "        for k in top_ranks:\n",
    "            if r is not None and r <= k:\n",
    "                rank_hits[k] += 1\n",
    "\n",
    "        if (idx_probe + 1) % 50 == 0 or idx_probe == total - 1:\n",
    "            print(f\"Processed {idx_probe+1}/{total} probes...\")\n",
    "\n",
    "    # compute identification rates\n",
    "    for k in top_ranks:\n",
    "        rate = rank_hits[k] / total\n",
    "        print(f\"Rank-{k} identification rate: {rate:.4f}  ({rank_hits[k]}/{total})\")\n",
    "\n",
    "    return rank_hits\n",
    "\n",
    "\n",
    "# ========== MAIN ==========\n",
    "def main():\n",
    "    # 1) Load index and split gallery / probes\n",
    "    gallery_df, probes_df = load_index_and_split(INDEX_CSV, alter_level_probe=ALTER_LEVEL_PROBE, max_probes=MAX_PROBES)\n",
    "\n",
    "    # 2) Load SNN embedding model\n",
    "    snn_model = SiameseNetworkEmbedding(input_dim=128, embedding_dim=128).to(device)\n",
    "    state = torch.load(MODEL_PATH, map_location=device)\n",
    "    # state is from SiameseNetwork with .branch, so extract matching keys\n",
    "    # If saved with SiameseNetwork, keys are like \"branch.net.0.weight\", etc.\n",
    "    # This will still load fine into SiameseNetworkEmbedding.branch\n",
    "    snn_model.load_state_dict(state, strict=False)\n",
    "    snn_model.eval()\n",
    "    print(f\"Loaded SNN embedding model from {MODEL_PATH}\")\n",
    "\n",
    "    # 3) Precompute gallery embeddings\n",
    "    gallery_feats, gallery_embs = compute_gallery_embeddings(snn_model, gallery_df)\n",
    "    gallery_embs = gallery_embs.to(device)\n",
    "\n",
    "    # 4) Prepare gallery descriptor cache\n",
    "    des_paths_gallery, des_cache = build_gallery_descriptor_cache(gallery_df)\n",
    "\n",
    "    # 5) Run 1:N evaluation\n",
    "    print(\"\\n=== 1:N Identification Evaluation ===\")\n",
    "    evaluate_identification(\n",
    "        gallery_df,\n",
    "        probes_df,\n",
    "        gallery_embs,\n",
    "        snn_model,\n",
    "        des_paths_gallery,\n",
    "        des_cache,\n",
    "        top_k1=TOP_K1,\n",
    "        top_ranks=TOP_RANKS,\n",
    "        ratio_thresh=RATIO_THRESH,\n",
    "        snn_weight=SNN_WEIGHT,\n",
    "        el_weight=EL_WEIGHT\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ef343c9-7797-490d-8af8-827b78db5dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Gallery population size (real fingerprints): 12000\n",
      "Loaded SNN embedding model from: D:\\5th sem\\mini_project\\models\\snn_sift_agg_best.pt\n",
      "\n",
      "Computing features for query image: D:\\5th sem\\mini_project\\dataset\\SOCOFing\\Altered\\Altered-Medium\\1__M_Left_index_finger_Obl.BMP\n",
      "\n",
      "================= TOP MATCHES (FUSED) =================\n",
      "1. subject=1, finger=index_finger, fused_score=0.7715, SNN_sim=0.8765, elastic=0.6664\n",
      "     image_path: D:\\5th sem\\mini_project\\dataset\\SOCOFing\\Real\\1__M_Left_index_finger.BMP\n",
      "2. subject=1, finger=index_finger, fused_score=0.7715, SNN_sim=0.8765, elastic=0.6664\n",
      "     image_path: D:\\5th sem\\mini_project\\dataset\\SOCOFing\\Real\\1__M_Left_index_finger.BMP\n",
      "3. subject=359, finger=middle_finger, fused_score=0.4509, SNN_sim=0.8886, elastic=0.0133\n",
      "     image_path: D:\\5th sem\\mini_project\\dataset\\SOCOFing\\Real\\359__M_Right_middle_finger.BMP\n",
      "\n",
      "Done. This list is your 'prospective criminals' list for this query.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ======================================================\n",
    "#                 EDIT THESE PATHS\n",
    "# ======================================================\n",
    "INDEX_CSV = r\"D:\\5th sem\\mini_project\\dataset\\socofing_index_features.csv\"\n",
    "MODEL_PATH = r\"D:\\5th sem\\mini_project\\models\\snn_sift_agg_best.pt\"\n",
    "\n",
    "# Query fingerprint (crime-scene sample)\n",
    "QUERY_IMAGE = r\"D:\\5th sem\\mini_project\\dataset\\SOCOFing\\Altered\\Altered-Medium\\1__M_Left_index_finger_Obl.BMP\"  # <-- change to your test image path\n",
    "\n",
    "# Size and preprocessing must match your SIFT pipeline\n",
    "IMG_SIZE = (512, 512)\n",
    "\n",
    "TOP_K1 = 200   # SNN preselection size for elastic refinement\n",
    "TOP_K  = 3    # final number of suspects shown\n",
    "\n",
    "RATIO_THRESH = 0.75  # Lowe ratio for elastic matching\n",
    "SNN_WEIGHT   = 0.5   # fusion weights\n",
    "EL_WEIGHT    = 0.5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "#         MODEL (same architecture as training)\n",
    "# ======================================================\n",
    "class SiameseBranch(nn.Module):\n",
    "    def __init__(self, input_dim=128, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, embedding_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class SiameseNetworkEmbedding(nn.Module):\n",
    "    \"\"\"Single-branch encoder to get embedding from 128-D feature.\"\"\"\n",
    "    def __init__(self, input_dim=128, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        self.branch = SiameseBranch(input_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.branch(x)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "#            SIFT PREPROCESSING FOR QUERY\n",
    "# ======================================================\n",
    "def preprocess_image(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        raise RuntimeError(f\"Cannot read image: {img_path}\")\n",
    "    img = cv2.resize(img, IMG_SIZE)\n",
    "    img = cv2.equalizeHist(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def compute_query_features(img_path):\n",
    "    \"\"\"\n",
    "    Compute:\n",
    "      - agg_vector: 128-D mean SIFT descriptor (for SNN)\n",
    "      - des_full: full [N,128] SIFT descriptors (for elastic)\n",
    "    \"\"\"\n",
    "    img = preprocess_image(img_path)\n",
    "    sift = cv2.SIFT_create()\n",
    "    kps, des = sift.detectAndCompute(img, None)\n",
    "\n",
    "    if des is None or len(des) == 0:\n",
    "        # no descriptors: return zero agg and None full\n",
    "        agg_vec = np.zeros(128, dtype=np.float32)\n",
    "        return agg_vec, None\n",
    "\n",
    "    # mean descriptor, center and L2 normalize (same as your pipeline)\n",
    "    v = des.astype(np.float32).mean(axis=0)\n",
    "    v = v - v.mean()\n",
    "    n = np.linalg.norm(v)\n",
    "    if n < 1e-12:\n",
    "        agg_vec = np.zeros(128, dtype=np.float32)\n",
    "    else:\n",
    "        agg_vec = (v / n).astype(np.float32)\n",
    "\n",
    "    return agg_vec, des.astype(np.float32)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "#          ELASTIC SIFT MATCHING SCORE\n",
    "# ======================================================\n",
    "def compute_elastic_score(des1, des2, ratio_thresh=0.75):\n",
    "    \"\"\"Lowe's ratio test, normalized good matches count ∈ [0,1].\"\"\"\n",
    "    if des1 is None or des2 is None or len(des1) < 2 or len(des2) < 2:\n",
    "        return 0.0\n",
    "\n",
    "    des1 = des1.astype(np.float32)\n",
    "    des2 = des2.astype(np.float32)\n",
    "\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < ratio_thresh * n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    good_count = len(good)\n",
    "    denom = max(len(des1), len(des2))\n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "    return good_count / float(denom)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "#         LOAD GALLERY (POPULATION) FROM CSV\n",
    "# ======================================================\n",
    "def load_gallery(index_csv):\n",
    "    df = pd.read_csv(index_csv)\n",
    "\n",
    "    # Example: use all REAL fingerprints as gallery (population)\n",
    "    gallery_df = df[df[\"real_or_altered\"].str.lower() == \"real\"].copy()\n",
    "    gallery_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(\"Gallery population size (real fingerprints):\", len(gallery_df))\n",
    "    return gallery_df\n",
    "\n",
    "\n",
    "def load_gallery_agg_features(gallery_df):\n",
    "    agg_paths = gallery_df[\"agg_path\"].tolist()\n",
    "    feats = []\n",
    "    for p in agg_paths:\n",
    "        v = np.load(p).astype(np.float32)  # [128]\n",
    "        feats.append(v)\n",
    "    feats = np.stack(feats, axis=0)  # [N_gallery, 128]\n",
    "    return torch.from_numpy(feats).to(device)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "#      MAIN SEARCH: SINGLE QUERY vs FULL POPULATION\n",
    "# ======================================================\n",
    "def main():\n",
    "    # 1) Load gallery metadata\n",
    "    gallery_df = load_gallery(INDEX_CSV)\n",
    "\n",
    "    # 2) Load SNN embedding model\n",
    "    snn_model = SiameseNetworkEmbedding(input_dim=128, embedding_dim=128).to(device)\n",
    "    state = torch.load(MODEL_PATH, map_location=device)\n",
    "    snn_model.load_state_dict(state, strict=False)\n",
    "    snn_model.eval()\n",
    "    print(\"Loaded SNN embedding model from:\", MODEL_PATH)\n",
    "\n",
    "    # 3) Precompute gallery embeddings\n",
    "    gallery_feats = load_gallery_agg_features(gallery_df)  # [N_gallery,128]\n",
    "    with torch.no_grad():\n",
    "        gallery_embs = snn_model(gallery_feats).cpu().numpy()  # [N_gallery,emb_dim]\n",
    "    gallery_feats = gallery_feats.cpu().numpy()\n",
    "\n",
    "    # 4) Compute query features (agg + full SIFT descriptors)\n",
    "    print(\"\\nComputing features for query image:\", QUERY_IMAGE)\n",
    "    q_agg, q_des = compute_query_features(QUERY_IMAGE)\n",
    "    q_agg_t = torch.from_numpy(q_agg).unsqueeze(0).to(device)  # [1,128]\n",
    "    with torch.no_grad():\n",
    "        q_emb = snn_model(q_agg_t).cpu().numpy()[0]  # [emb_dim]\n",
    "\n",
    "    # 5) SNN similarity to all gallery\n",
    "    dists = np.linalg.norm(gallery_embs - q_emb, axis=1)      # [N_gallery]\n",
    "    snn_sim = 1.0 / (1.0 + dists)                             # similarity ∈ (0,1]\n",
    "\n",
    "    # 6) Take top-K1 by SNN similarity\n",
    "    N_gallery = len(gallery_df)\n",
    "    k1 = min(TOP_K1, N_gallery)\n",
    "    idx_sorted = np.argsort(-snn_sim)     # descending similarity\n",
    "    cand_idx = idx_sorted[:k1]           # candidate indices in gallery\n",
    "\n",
    "    # 7) Elastic matching on top-K1\n",
    "    des_cache = {}\n",
    "    elastic_scores = np.zeros(k1, dtype=np.float32)\n",
    "\n",
    "    if q_des is None:\n",
    "        print(\"Warning: query has no SIFT descriptors; elastic scores will be zero.\")\n",
    "\n",
    "    for i, g_idx in enumerate(cand_idx):\n",
    "        des_path_g = gallery_df.loc[g_idx, \"des_path\"]\n",
    "        if des_path_g not in des_cache:\n",
    "            if os.path.exists(des_path_g):\n",
    "                des_cache[des_path_g] = np.load(des_path_g).astype(np.float32)\n",
    "            else:\n",
    "                des_cache[des_path_g] = None\n",
    "\n",
    "        des_g = des_cache[des_path_g]\n",
    "        elastic_scores[i] = compute_elastic_score(q_des, des_g, ratio_thresh=RATIO_THRESH)\n",
    "\n",
    "    # 8) Fuse SNN similarity and elastic scores\n",
    "    snn_sim_top = snn_sim[cand_idx]\n",
    "    fused = SNN_WEIGHT * snn_sim_top + EL_WEIGHT * elastic_scores\n",
    "\n",
    "    # 9) Sort final candidates by fused score\n",
    "    order = np.argsort(-fused)\n",
    "    final_idx = cand_idx[order]\n",
    "    final_scores = fused[order]\n",
    "\n",
    "    # 10) Print top-K results with subject IDs and info\n",
    "    K = min(TOP_K, len(final_idx))\n",
    "    print(\"\\n================= TOP MATCHES (FUSED) =================\")\n",
    "    for rank in range(K):\n",
    "        g_idx = final_idx[rank]\n",
    "        row = gallery_df.loc[g_idx]\n",
    "\n",
    "        subj = row[\"subject_id\"]\n",
    "        finger = row[\"finger\"]\n",
    "        img_path = row[\"image_path\"]\n",
    "        s_snn = snn_sim[g_idx]\n",
    "        s_el  = elastic_scores[order[rank]]\n",
    "\n",
    "        print(f\"{rank+1}. subject={subj}, finger={finger}, \"\n",
    "              f\"fused_score={final_scores[rank]:.4f}, \"\n",
    "              f\"SNN_sim={s_snn:.4f}, elastic={s_el:.4f}\")\n",
    "        print(f\"     image_path: {img_path}\")\n",
    "\n",
    "    print(\"\\nDone. This list is your 'prospective criminals' list for this query.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62b12ff7-463e-48ef-8352-ae34a6099853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Gallery population size (real fingerprints): 12000\n",
      "Loaded SNN embedding model from: D:\\5th sem\\mini_project\\models\\snn_sift_agg_best.pt\n",
      "\n",
      "Computing features for query image: D:\\Desktop\\new\\images\\starbucks-logo-png-transparent-0.png\n",
      "\n",
      "================= TOP MATCHES (FUSED) =================\n",
      "1. subject=217, finger=middle_finger, fused_score=0.3297, SNN_sim=0.6315, elastic=0.0280\n",
      "     image_path: D:\\5th sem\\mini_project\\dataset\\SOCOFing\\Real\\217__M_Right_middle_finger.BMP\n",
      "2. subject=217, finger=middle_finger, fused_score=0.3297, SNN_sim=0.6315, elastic=0.0280\n",
      "     image_path: D:\\5th sem\\mini_project\\dataset\\SOCOFing\\Real\\217__M_Right_middle_finger.BMP\n",
      "3. subject=217, finger=thumb_finger, fused_score=0.3238, SNN_sim=0.6386, elastic=0.0091\n",
      "     image_path: D:\\5th sem\\mini_project\\dataset\\SOCOFing\\Real\\217__M_Right_thumb_finger.BMP\n",
      "\n",
      "Done. This list is your 'prospective criminals' list for this query.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ======================================================\n",
    "#                 EDIT THESE PATHS\n",
    "# ======================================================\n",
    "INDEX_CSV = r\"D:\\5th sem\\mini_project\\dataset\\socofing_index_features.csv\"\n",
    "MODEL_PATH = r\"D:\\5th sem\\mini_project\\models\\snn_sift_agg_best.pt\"\n",
    "\n",
    "# Query fingerprint (crime-scene sample)\n",
    "QUERY_IMAGE = r\"D:\\Desktop\\new\\images\\starbucks-logo-png-transparent-0.png\"  # <-- change to your test image path\n",
    "\n",
    "# Size and preprocessing must match your SIFT pipeline\n",
    "IMG_SIZE = (512, 512)\n",
    "\n",
    "TOP_K1 = 200   # SNN preselection size for elastic refinement\n",
    "TOP_K  = 3    # final number of suspects shown\n",
    "\n",
    "RATIO_THRESH = 0.75  # Lowe ratio for elastic matching\n",
    "SNN_WEIGHT   = 0.5   # fusion weights\n",
    "EL_WEIGHT    = 0.5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "#         MODEL (same architecture as training)\n",
    "# ======================================================\n",
    "class SiameseBranch(nn.Module):\n",
    "    def __init__(self, input_dim=128, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, embedding_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class SiameseNetworkEmbedding(nn.Module):\n",
    "    \"\"\"Single-branch encoder to get embedding from 128-D feature.\"\"\"\n",
    "    def __init__(self, input_dim=128, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        self.branch = SiameseBranch(input_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.branch(x)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "#            SIFT PREPROCESSING FOR QUERY\n",
    "# ======================================================\n",
    "def preprocess_image(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        raise RuntimeError(f\"Cannot read image: {img_path}\")\n",
    "    img = cv2.resize(img, IMG_SIZE)\n",
    "    img = cv2.equalizeHist(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def compute_query_features(img_path):\n",
    "    \"\"\"\n",
    "    Compute:\n",
    "      - agg_vector: 128-D mean SIFT descriptor (for SNN)\n",
    "      - des_full: full [N,128] SIFT descriptors (for elastic)\n",
    "    \"\"\"\n",
    "    img = preprocess_image(img_path)\n",
    "    sift = cv2.SIFT_create()\n",
    "    kps, des = sift.detectAndCompute(img, None)\n",
    "\n",
    "    if des is None or len(des) == 0:\n",
    "        # no descriptors: return zero agg and None full\n",
    "        agg_vec = np.zeros(128, dtype=np.float32)\n",
    "        return agg_vec, None\n",
    "\n",
    "    # mean descriptor, center and L2 normalize (same as your pipeline)\n",
    "    v = des.astype(np.float32).mean(axis=0)\n",
    "    v = v - v.mean()\n",
    "    n = np.linalg.norm(v)\n",
    "    if n < 1e-12:\n",
    "        agg_vec = np.zeros(128, dtype=np.float32)\n",
    "    else:\n",
    "        agg_vec = (v / n).astype(np.float32)\n",
    "\n",
    "    return agg_vec, des.astype(np.float32)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "#          ELASTIC SIFT MATCHING SCORE\n",
    "# ======================================================\n",
    "def compute_elastic_score(des1, des2, ratio_thresh=0.75):\n",
    "    \"\"\"Lowe's ratio test, normalized good matches count ∈ [0,1].\"\"\"\n",
    "    if des1 is None or des2 is None or len(des1) < 2 or len(des2) < 2:\n",
    "        return 0.0\n",
    "\n",
    "    des1 = des1.astype(np.float32)\n",
    "    des2 = des2.astype(np.float32)\n",
    "\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < ratio_thresh * n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    good_count = len(good)\n",
    "    denom = max(len(des1), len(des2))\n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "    return good_count / float(denom)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "#         LOAD GALLERY (POPULATION) FROM CSV\n",
    "# ======================================================\n",
    "def load_gallery(index_csv):\n",
    "    df = pd.read_csv(index_csv)\n",
    "\n",
    "    # Example: use all REAL fingerprints as gallery (population)\n",
    "    gallery_df = df[df[\"real_or_altered\"].str.lower() == \"real\"].copy()\n",
    "    gallery_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(\"Gallery population size (real fingerprints):\", len(gallery_df))\n",
    "    return gallery_df\n",
    "\n",
    "\n",
    "def load_gallery_agg_features(gallery_df):\n",
    "    agg_paths = gallery_df[\"agg_path\"].tolist()\n",
    "    feats = []\n",
    "    for p in agg_paths:\n",
    "        v = np.load(p).astype(np.float32)  # [128]\n",
    "        feats.append(v)\n",
    "    feats = np.stack(feats, axis=0)  # [N_gallery, 128]\n",
    "    return torch.from_numpy(feats).to(device)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "#      MAIN SEARCH: SINGLE QUERY vs FULL POPULATION\n",
    "# ======================================================\n",
    "def main():\n",
    "    # 1) Load gallery metadata\n",
    "    gallery_df = load_gallery(INDEX_CSV)\n",
    "\n",
    "    # 2) Load SNN embedding model\n",
    "    snn_model = SiameseNetworkEmbedding(input_dim=128, embedding_dim=128).to(device)\n",
    "    state = torch.load(MODEL_PATH, map_location=device)\n",
    "    snn_model.load_state_dict(state, strict=False)\n",
    "    snn_model.eval()\n",
    "    print(\"Loaded SNN embedding model from:\", MODEL_PATH)\n",
    "\n",
    "    # 3) Precompute gallery embeddings\n",
    "    gallery_feats = load_gallery_agg_features(gallery_df)  # [N_gallery,128]\n",
    "    with torch.no_grad():\n",
    "        gallery_embs = snn_model(gallery_feats).cpu().numpy()  # [N_gallery,emb_dim]\n",
    "    gallery_feats = gallery_feats.cpu().numpy()\n",
    "\n",
    "    # 4) Compute query features (agg + full SIFT descriptors)\n",
    "    print(\"\\nComputing features for query image:\", QUERY_IMAGE)\n",
    "    q_agg, q_des = compute_query_features(QUERY_IMAGE)\n",
    "    q_agg_t = torch.from_numpy(q_agg).unsqueeze(0).to(device)  # [1,128]\n",
    "    with torch.no_grad():\n",
    "        q_emb = snn_model(q_agg_t).cpu().numpy()[0]  # [emb_dim]\n",
    "\n",
    "    # 5) SNN similarity to all gallery\n",
    "    dists = np.linalg.norm(gallery_embs - q_emb, axis=1)      # [N_gallery]\n",
    "    snn_sim = 1.0 / (1.0 + dists)                             # similarity ∈ (0,1]\n",
    "\n",
    "    # 6) Take top-K1 by SNN similarity\n",
    "    N_gallery = len(gallery_df)\n",
    "    k1 = min(TOP_K1, N_gallery)\n",
    "    idx_sorted = np.argsort(-snn_sim)     # descending similarity\n",
    "    cand_idx = idx_sorted[:k1]           # candidate indices in gallery\n",
    "\n",
    "    # 7) Elastic matching on top-K1\n",
    "    des_cache = {}\n",
    "    elastic_scores = np.zeros(k1, dtype=np.float32)\n",
    "\n",
    "    if q_des is None:\n",
    "        print(\"Warning: query has no SIFT descriptors; elastic scores will be zero.\")\n",
    "\n",
    "    for i, g_idx in enumerate(cand_idx):\n",
    "        des_path_g = gallery_df.loc[g_idx, \"des_path\"]\n",
    "        if des_path_g not in des_cache:\n",
    "            if os.path.exists(des_path_g):\n",
    "                des_cache[des_path_g] = np.load(des_path_g).astype(np.float32)\n",
    "            else:\n",
    "                des_cache[des_path_g] = None\n",
    "\n",
    "        des_g = des_cache[des_path_g]\n",
    "        elastic_scores[i] = compute_elastic_score(q_des, des_g, ratio_thresh=RATIO_THRESH)\n",
    "\n",
    "    # 8) Fuse SNN similarity and elastic scores\n",
    "    snn_sim_top = snn_sim[cand_idx]\n",
    "    fused = SNN_WEIGHT * snn_sim_top + EL_WEIGHT * elastic_scores\n",
    "\n",
    "    # 9) Sort final candidates by fused score\n",
    "    order = np.argsort(-fused)\n",
    "    final_idx = cand_idx[order]\n",
    "    final_scores = fused[order]\n",
    "\n",
    "    # 10) Print top-K results with subject IDs and info\n",
    "    K = min(TOP_K, len(final_idx))\n",
    "    print(\"\\n================= TOP MATCHES (FUSED) =================\")\n",
    "    for rank in range(K):\n",
    "        g_idx = final_idx[rank]\n",
    "        row = gallery_df.loc[g_idx]\n",
    "\n",
    "        subj = row[\"subject_id\"]\n",
    "        finger = row[\"finger\"]\n",
    "        img_path = row[\"image_path\"]\n",
    "        s_snn = snn_sim[g_idx]\n",
    "        s_el  = elastic_scores[order[rank]]\n",
    "\n",
    "        print(f\"{rank+1}. subject={subj}, finger={finger}, \"\n",
    "              f\"fused_score={final_scores[rank]:.4f}, \"\n",
    "              f\"SNN_sim={s_snn:.4f}, elastic={s_el:.4f}\")\n",
    "        print(f\"     image_path: {img_path}\")\n",
    "\n",
    "    print(\"\\nDone. This list is your 'prospective criminals' list for this query.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68841efd-1b65-4a11-b5e2-b592869477b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Gallery population size (real fingerprints): 12000\n",
      "Loaded SNN embedding model from: D:\\5th sem\\mini_project\\models\\snn_sift_agg_best.pt\n",
      "\n",
      "Computing features for query image: D:\\Desktop\\new\\images\\starbucks-logo-png-transparent-0.png\n",
      "\n",
      "Best fused score across population: 0.3297\n",
      "Decision: NO RELIABLE MATCH FOUND (fused score below threshold).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ======================================================\n",
    "#                 EDIT THESE PATHS\n",
    "# ======================================================\n",
    "INDEX_CSV = r\"D:\\5th sem\\mini_project\\dataset\\socofing_index_features.csv\"\n",
    "MODEL_PATH = r\"D:\\5th sem\\mini_project\\models\\snn_sift_agg_best.pt\"\n",
    "\n",
    "# Crime-scene query fingerprint\n",
    "QUERY_IMAGE = r\"D:\\Desktop\\new\\images\\starbucks-logo-png-transparent-0.png\"  # change to your test file\n",
    "\n",
    "IMG_SIZE = (512, 512)\n",
    "\n",
    "TOP_K1 = 200   # SNN preselection for elastic refinement\n",
    "TOP_K  = 3     # final number of suspects to display\n",
    "\n",
    "RATIO_THRESH = 0.75\n",
    "SNN_WEIGHT   = 0.5\n",
    "EL_WEIGHT    = 0.5\n",
    "\n",
    "# === IMPORTANT: decision threshold on fused score ===\n",
    "# Set this based on your fusion calibration script (best_thr_fus or tighter).\n",
    "FUSION_DECISION_THR = 0.6   # example; adjust after looking at fusion_val distribution\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "#         MODEL (same as training)\n",
    "# ======================================================\n",
    "class SiameseBranch(nn.Module):\n",
    "    def __init__(self, input_dim=128, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, embedding_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class SiameseNetworkEmbedding(nn.Module):\n",
    "    def __init__(self, input_dim=128, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        self.branch = SiameseBranch(input_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.branch(x)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "#            SIFT PREPROCESSING FOR QUERY\n",
    "# ======================================================\n",
    "def preprocess_image(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        raise RuntimeError(f\"Cannot read image: {img_path}\")\n",
    "    img = cv2.resize(img, IMG_SIZE)\n",
    "    img = cv2.equalizeHist(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def compute_query_features(img_path):\n",
    "    img = preprocess_image(img_path)\n",
    "    sift = cv2.SIFT_create()\n",
    "    kps, des = sift.detectAndCompute(img, None)\n",
    "\n",
    "    if des is None or len(des) == 0:\n",
    "        agg_vec = np.zeros(128, dtype=np.float32)\n",
    "        return agg_vec, None\n",
    "\n",
    "    v = des.astype(np.float32).mean(axis=0)\n",
    "    v = v - v.mean()\n",
    "    n = np.linalg.norm(v)\n",
    "    if n < 1e-12:\n",
    "        agg_vec = np.zeros(128, dtype=np.float32)\n",
    "    else:\n",
    "        agg_vec = (v / n).astype(np.float32)\n",
    "\n",
    "    return agg_vec, des.astype(np.float32)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "#          ELASTIC SIFT MATCHING SCORE\n",
    "# ======================================================\n",
    "def compute_elastic_score(des1, des2, ratio_thresh=0.75):\n",
    "    if des1 is None or des2 is None or len(des1) < 2 or len(des2) < 2:\n",
    "        return 0.0\n",
    "\n",
    "    des1 = des1.astype(np.float32)\n",
    "    des2 = des2.astype(np.float32)\n",
    "\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < ratio_thresh * n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    good_count = len(good)\n",
    "    denom = max(len(des1), len(des2))\n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "    return good_count / float(denom)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "#         LOAD GALLERY (POPULATION)\n",
    "# ======================================================\n",
    "def load_gallery(index_csv):\n",
    "    df = pd.read_csv(index_csv)\n",
    "    gallery_df = df[df[\"real_or_altered\"].str.lower() == \"real\"].copy()\n",
    "    gallery_df.reset_index(drop=True, inplace=True)\n",
    "    print(\"Gallery population size (real fingerprints):\", len(gallery_df))\n",
    "    return gallery_df\n",
    "\n",
    "\n",
    "def load_gallery_agg_features(gallery_df):\n",
    "    agg_paths = gallery_df[\"agg_path\"].tolist()\n",
    "    feats = []\n",
    "    for p in agg_paths:\n",
    "        v = np.load(p).astype(np.float32)\n",
    "        feats.append(v)\n",
    "    feats = np.stack(feats, axis=0)\n",
    "    return torch.from_numpy(feats).to(device)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "#      MAIN SEARCH + DECISION LAYER\n",
    "# ======================================================\n",
    "def main():\n",
    "    # 1) Load gallery\n",
    "    gallery_df = load_gallery(INDEX_CSV)\n",
    "\n",
    "    # 2) Load SNN embedding model\n",
    "    snn_model = SiameseNetworkEmbedding(input_dim=128, embedding_dim=128).to(device)\n",
    "    state = torch.load(MODEL_PATH, map_location=device)\n",
    "    snn_model.load_state_dict(state, strict=False)\n",
    "    snn_model.eval()\n",
    "    print(\"Loaded SNN embedding model from:\", MODEL_PATH)\n",
    "\n",
    "    # 3) Precompute gallery embeddings\n",
    "    gallery_feats = load_gallery_agg_features(gallery_df)   # [N,128]\n",
    "    with torch.no_grad():\n",
    "        gallery_embs = snn_model(gallery_feats).cpu().numpy()\n",
    "    gallery_feats = gallery_feats.cpu().numpy()\n",
    "\n",
    "    # 4) Query features\n",
    "    print(\"\\nComputing features for query image:\", QUERY_IMAGE)\n",
    "    q_agg, q_des = compute_query_features(QUERY_IMAGE)\n",
    "\n",
    "    if q_des is None or len(q_des) == 0:\n",
    "        print(\"Query fingerprint has no SIFT descriptors; cannot match reliably.\")\n",
    "        print(\"Decision: NO MATCH FOUND.\")\n",
    "        return\n",
    "\n",
    "    q_agg_t = torch.from_numpy(q_agg).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        q_emb = snn_model(q_agg_t).cpu().numpy()[0]\n",
    "\n",
    "    # 5) SNN similarity to all gallery\n",
    "    dists = np.linalg.norm(gallery_embs - q_emb, axis=1)\n",
    "    snn_sim = 1.0 / (1.0 + dists)  # [0,1]\n",
    "\n",
    "    # 6) Take top-K1 by SNN similarity\n",
    "    N_gallery = len(gallery_df)\n",
    "    k1 = min(TOP_K1, N_gallery)\n",
    "    idx_sorted = np.argsort(-snn_sim)\n",
    "    cand_idx = idx_sorted[:k1]\n",
    "\n",
    "    # 7) Elastic scores for top-K1\n",
    "    des_cache = {}\n",
    "    elastic_scores = np.zeros(k1, dtype=np.float32)\n",
    "\n",
    "    for i, g_idx in enumerate(cand_idx):\n",
    "        des_path_g = gallery_df.loc[g_idx, \"des_path\"]\n",
    "        if des_path_g not in des_cache:\n",
    "            if os.path.exists(des_path_g):\n",
    "                des_cache[des_path_g] = np.load(des_path_g).astype(np.float32)\n",
    "            else:\n",
    "                des_cache[des_path_g] = None\n",
    "        des_g = des_cache[des_path_g]\n",
    "        elastic_scores[i] = compute_elastic_score(q_des, des_g, ratio_thresh=RATIO_THRESH)\n",
    "\n",
    "    # 8) Fused scores\n",
    "    snn_sim_top = snn_sim[cand_idx]\n",
    "    fused = SNN_WEIGHT * snn_sim_top + EL_WEIGHT * elastic_scores\n",
    "\n",
    "    # 9) Decision: is there a reliable match?\n",
    "    best_idx_local = int(np.argmax(fused))\n",
    "    best_fused_score = float(fused[best_idx_local])\n",
    "    best_gallery_idx = int(cand_idx[best_idx_local])\n",
    "\n",
    "    print(f\"\\nBest fused score across population: {best_fused_score:.4f}\")\n",
    "    if best_fused_score < FUSION_DECISION_THR:\n",
    "        print(\"Decision: NO RELIABLE MATCH FOUND (fused score below threshold).\")\n",
    "        return\n",
    "\n",
    "    print(\"Decision: MATCH FOUND. Showing top suspects...\\n\")\n",
    "\n",
    "    # 10) Rank and print top-K suspects\n",
    "    order = np.argsort(-fused)\n",
    "    final_idx = cand_idx[order]\n",
    "    final_scores = fused[order]\n",
    "\n",
    "    K = min(TOP_K, len(final_idx))\n",
    "    print(\"=============== TOP SUSPECTS ===============\")\n",
    "    for rank in range(K):\n",
    "        g_idx = final_idx[rank]\n",
    "        row = gallery_df.loc[g_idx]\n",
    "\n",
    "        subj = row[\"subject_id\"]\n",
    "        finger = row[\"finger\"]\n",
    "        img_path = row[\"image_path\"]\n",
    "\n",
    "        s_snn = snn_sim[g_idx]\n",
    "        s_el  = elastic_scores[order[rank]]\n",
    "\n",
    "        print(f\"{rank+1}. subject={subj}, finger={finger}, \"\n",
    "              f\"fused_score={final_scores[rank]:.4f}, \"\n",
    "              f\"SNN_sim={s_snn:.4f}, elastic={s_el:.4f}\")\n",
    "        print(f\"     enrolled_image: {img_path}\")\n",
    "\n",
    "    print(\"\\nDone.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc5f302f-984e-4387-8f46-d15ea2a9f0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Gallery population size (real fingerprints): 12000\n",
      "Loaded SNN embedding model from: D:\\5th sem\\mini_project\\models\\snn_sift_agg_best.pt\n",
      "\n",
      "Computing features for query image: D:\\5th sem\\mini_project\\dataset\\SOCOFing\\Altered\\Altered-Medium\\1__M_Right_little_finger_CR.BMP\n",
      "\n",
      "Best fused score across population: 0.7320\n",
      "Decision: MATCH FOUND. Showing top suspects...\n",
      "\n",
      "=============== TOP SUSPECTS ===============\n",
      "1. subject=1, finger=little_finger, fused_score=0.7320, SNN_sim=0.8765, elastic=0.5876\n",
      "     enrolled_image: D:\\5th sem\\mini_project\\dataset\\SOCOFing\\Real\\1__M_Right_little_finger.BMP\n",
      "2. subject=1, finger=little_finger, fused_score=0.7320, SNN_sim=0.8765, elastic=0.5876\n",
      "     enrolled_image: D:\\5th sem\\mini_project\\dataset\\SOCOFing\\Real\\1__M_Right_little_finger.BMP\n",
      "3. subject=484, finger=middle_finger, fused_score=0.4658, SNN_sim=0.9136, elastic=0.0179\n",
      "     enrolled_image: D:\\5th sem\\mini_project\\dataset\\SOCOFing\\Real\\484__M_Left_middle_finger.BMP\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ======================================================\n",
    "#                 EDIT THESE PATHS\n",
    "# ======================================================\n",
    "INDEX_CSV = r\"D:\\5th sem\\mini_project\\dataset\\socofing_index_features.csv\"\n",
    "MODEL_PATH = r\"D:\\5th sem\\mini_project\\models\\snn_sift_agg_best.pt\"\n",
    "\n",
    "# Crime-scene query fingerprint\n",
    "QUERY_IMAGE = r\"D:\\5th sem\\mini_project\\dataset\\SOCOFing\\Altered\\Altered-Medium\\1__M_Right_little_finger_CR.BMP\"  # change to your test file\n",
    "\n",
    "IMG_SIZE = (512, 512)\n",
    "\n",
    "TOP_K1 = 200   # SNN preselection for elastic refinement\n",
    "TOP_K  = 3     # final number of suspects to display\n",
    "\n",
    "RATIO_THRESH = 0.75\n",
    "SNN_WEIGHT   = 0.5\n",
    "EL_WEIGHT    = 0.5\n",
    "\n",
    "# === IMPORTANT: decision threshold on fused score ===\n",
    "# Set this based on your fusion calibration script (best_thr_fus or tighter).\n",
    "FUSION_DECISION_THR = 0.6   # example; adjust after looking at fusion_val distribution\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "#         MODEL (same as training)\n",
    "# ======================================================\n",
    "class SiameseBranch(nn.Module):\n",
    "    def __init__(self, input_dim=128, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, embedding_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class SiameseNetworkEmbedding(nn.Module):\n",
    "    def __init__(self, input_dim=128, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        self.branch = SiameseBranch(input_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.branch(x)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "#            SIFT PREPROCESSING FOR QUERY\n",
    "# ======================================================\n",
    "def preprocess_image(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        raise RuntimeError(f\"Cannot read image: {img_path}\")\n",
    "    img = cv2.resize(img, IMG_SIZE)\n",
    "    img = cv2.equalizeHist(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def compute_query_features(img_path):\n",
    "    img = preprocess_image(img_path)\n",
    "    sift = cv2.SIFT_create()\n",
    "    kps, des = sift.detectAndCompute(img, None)\n",
    "\n",
    "    if des is None or len(des) == 0:\n",
    "        agg_vec = np.zeros(128, dtype=np.float32)\n",
    "        return agg_vec, None\n",
    "\n",
    "    v = des.astype(np.float32).mean(axis=0)\n",
    "    v = v - v.mean()\n",
    "    n = np.linalg.norm(v)\n",
    "    if n < 1e-12:\n",
    "        agg_vec = np.zeros(128, dtype=np.float32)\n",
    "    else:\n",
    "        agg_vec = (v / n).astype(np.float32)\n",
    "\n",
    "    return agg_vec, des.astype(np.float32)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "#          ELASTIC SIFT MATCHING SCORE\n",
    "# ======================================================\n",
    "def compute_elastic_score(des1, des2, ratio_thresh=0.75):\n",
    "    if des1 is None or des2 is None or len(des1) < 2 or len(des2) < 2:\n",
    "        return 0.0\n",
    "\n",
    "    des1 = des1.astype(np.float32)\n",
    "    des2 = des2.astype(np.float32)\n",
    "\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < ratio_thresh * n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    good_count = len(good)\n",
    "    denom = max(len(des1), len(des2))\n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "    return good_count / float(denom)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "#         LOAD GALLERY (POPULATION)\n",
    "# ======================================================\n",
    "def load_gallery(index_csv):\n",
    "    df = pd.read_csv(index_csv)\n",
    "    gallery_df = df[df[\"real_or_altered\"].str.lower() == \"real\"].copy()\n",
    "    gallery_df.reset_index(drop=True, inplace=True)\n",
    "    print(\"Gallery population size (real fingerprints):\", len(gallery_df))\n",
    "    return gallery_df\n",
    "\n",
    "\n",
    "def load_gallery_agg_features(gallery_df):\n",
    "    agg_paths = gallery_df[\"agg_path\"].tolist()\n",
    "    feats = []\n",
    "    for p in agg_paths:\n",
    "        v = np.load(p).astype(np.float32)\n",
    "        feats.append(v)\n",
    "    feats = np.stack(feats, axis=0)\n",
    "    return torch.from_numpy(feats).to(device)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "#      MAIN SEARCH + DECISION LAYER\n",
    "# ======================================================\n",
    "def main():\n",
    "    # 1) Load gallery\n",
    "    gallery_df = load_gallery(INDEX_CSV)\n",
    "\n",
    "    # 2) Load SNN embedding model\n",
    "    snn_model = SiameseNetworkEmbedding(input_dim=128, embedding_dim=128).to(device)\n",
    "    state = torch.load(MODEL_PATH, map_location=device)\n",
    "    snn_model.load_state_dict(state, strict=False)\n",
    "    snn_model.eval()\n",
    "    print(\"Loaded SNN embedding model from:\", MODEL_PATH)\n",
    "\n",
    "    # 3) Precompute gallery embeddings\n",
    "    gallery_feats = load_gallery_agg_features(gallery_df)   # [N,128]\n",
    "    with torch.no_grad():\n",
    "        gallery_embs = snn_model(gallery_feats).cpu().numpy()\n",
    "    gallery_feats = gallery_feats.cpu().numpy()\n",
    "\n",
    "    # 4) Query features\n",
    "    print(\"\\nComputing features for query image:\", QUERY_IMAGE)\n",
    "    q_agg, q_des = compute_query_features(QUERY_IMAGE)\n",
    "\n",
    "    if q_des is None or len(q_des) == 0:\n",
    "        print(\"Query fingerprint has no SIFT descriptors; cannot match reliably.\")\n",
    "        print(\"Decision: NO MATCH FOUND.\")\n",
    "        return\n",
    "\n",
    "    q_agg_t = torch.from_numpy(q_agg).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        q_emb = snn_model(q_agg_t).cpu().numpy()[0]\n",
    "\n",
    "    # 5) SNN similarity to all gallery\n",
    "    dists = np.linalg.norm(gallery_embs - q_emb, axis=1)\n",
    "    snn_sim = 1.0 / (1.0 + dists)  # [0,1]\n",
    "\n",
    "    # 6) Take top-K1 by SNN similarity\n",
    "    N_gallery = len(gallery_df)\n",
    "    k1 = min(TOP_K1, N_gallery)\n",
    "    idx_sorted = np.argsort(-snn_sim)\n",
    "    cand_idx = idx_sorted[:k1]\n",
    "\n",
    "    # 7) Elastic scores for top-K1\n",
    "    des_cache = {}\n",
    "    elastic_scores = np.zeros(k1, dtype=np.float32)\n",
    "\n",
    "    for i, g_idx in enumerate(cand_idx):\n",
    "        des_path_g = gallery_df.loc[g_idx, \"des_path\"]\n",
    "        if des_path_g not in des_cache:\n",
    "            if os.path.exists(des_path_g):\n",
    "                des_cache[des_path_g] = np.load(des_path_g).astype(np.float32)\n",
    "            else:\n",
    "                des_cache[des_path_g] = None\n",
    "        des_g = des_cache[des_path_g]\n",
    "        elastic_scores[i] = compute_elastic_score(q_des, des_g, ratio_thresh=RATIO_THRESH)\n",
    "\n",
    "    # 8) Fused scores\n",
    "    snn_sim_top = snn_sim[cand_idx]\n",
    "    fused = SNN_WEIGHT * snn_sim_top + EL_WEIGHT * elastic_scores\n",
    "\n",
    "    # 9) Decision: is there a reliable match?\n",
    "    best_idx_local = int(np.argmax(fused))\n",
    "    best_fused_score = float(fused[best_idx_local])\n",
    "    best_gallery_idx = int(cand_idx[best_idx_local])\n",
    "\n",
    "    print(f\"\\nBest fused score across population: {best_fused_score:.4f}\")\n",
    "    if best_fused_score < FUSION_DECISION_THR:\n",
    "        print(\"Decision: NO RELIABLE MATCH FOUND (fused score below threshold).\")\n",
    "        return\n",
    "\n",
    "    print(\"Decision: MATCH FOUND. Showing top suspects...\\n\")\n",
    "\n",
    "    # 10) Rank and print top-K suspects\n",
    "    order = np.argsort(-fused)\n",
    "    final_idx = cand_idx[order]\n",
    "    final_scores = fused[order]\n",
    "\n",
    "    K = min(TOP_K, len(final_idx))\n",
    "    print(\"=============== TOP SUSPECTS ===============\")\n",
    "    for rank in range(K):\n",
    "        g_idx = final_idx[rank]\n",
    "        row = gallery_df.loc[g_idx]\n",
    "\n",
    "        subj = row[\"subject_id\"]\n",
    "        finger = row[\"finger\"]\n",
    "        img_path = row[\"image_path\"]\n",
    "\n",
    "        s_snn = snn_sim[g_idx]\n",
    "        s_el  = elastic_scores[order[rank]]\n",
    "\n",
    "        print(f\"{rank+1}. subject={subj}, finger={finger}, \"\n",
    "              f\"fused_score={final_scores[rank]:.4f}, \"\n",
    "              f\"SNN_sim={s_snn:.4f}, elastic={s_el:.4f}\")\n",
    "        print(f\"     enrolled_image: {img_path}\")\n",
    "\n",
    "    print(\"\\nDone.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fe32a2c-2027-4e85-a3b4-dd055ce7dd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SNN distances.\n",
      "SNN val pairs: 641121, test pairs: 665673\n",
      "\n",
      "=== SNN (VAL) ===\n",
      "Accuracy: 0.8350\n",
      "Precision: 0.8294\n",
      "Recall (TPR): 0.8021\n",
      "F1-score: 0.8155\n",
      "FAR (False Accept Rate): 0.1375\n",
      "FRR (False Reject Rate): 0.1979\n",
      "\n",
      "=== SNN (TEST) ===\n",
      "Accuracy: 0.8347\n",
      "Precision: 0.8327\n",
      "Recall (TPR): 0.7964\n",
      "F1-score: 0.8142\n",
      "FAR (False Accept Rate): 0.1333\n",
      "FRR (False Reject Rate): 0.2036\n",
      "\n",
      "Loaded elastic/fusion scores.\n",
      "Elastic/Fusion val pairs: 50000, test pairs: 50000\n",
      "\n",
      "=== ELASTIC (VAL) ===\n",
      "Accuracy: 0.7812\n",
      "Precision: 0.9284\n",
      "Recall (TPR): 0.5655\n",
      "F1-score: 0.7029\n",
      "FAR (False Accept Rate): 0.0368\n",
      "FRR (False Reject Rate): 0.4345\n",
      "\n",
      "=== ELASTIC (TEST) ===\n",
      "Accuracy: 0.7803\n",
      "Precision: 0.9364\n",
      "Recall (TPR): 0.5556\n",
      "F1-score: 0.6974\n",
      "FAR (False Accept Rate): 0.0316\n",
      "FRR (False Reject Rate): 0.4444\n",
      "\n",
      "=== FUSION (VAL) ===\n",
      "Accuracy: 0.8397\n",
      "Precision: 0.8338\n",
      "Recall (TPR): 0.8113\n",
      "F1-score: 0.8224\n",
      "FAR (False Accept Rate): 0.1364\n",
      "FRR (False Reject Rate): 0.1887\n",
      "\n",
      "=== FUSION (TEST) ===\n",
      "Accuracy: 0.8379\n",
      "Precision: 0.8353\n",
      "Recall (TPR): 0.8026\n",
      "F1-score: 0.8186\n",
      "FAR (False Accept Rate): 0.1325\n",
      "FRR (False Reject Rate): 0.1974\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# ========= CONFIG (edit paths if needed) =========\n",
    "SNN_NPZ     = r\"D:\\5th sem\\mini_project\\models\\snn_eval_distances.npz\"\n",
    "EL_FUS_NPZ  = r\"D:\\5th sem\\mini_project\\models\\elastic_fusion_scores.npz\"\n",
    "\n",
    "# Put your actual SNN best threshold here (distance threshold)\n",
    "BEST_THR_SNN = 0.5308  # example from your earlier eval, match if dist <= thr\n",
    "\n",
    "\n",
    "def compute_binary_metrics(labels, preds, name=\"\"):\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, zero_division=0)\n",
    "    rec = recall_score(labels, preds, zero_division=0)\n",
    "    f1 = f1_score(labels, preds, zero_division=0)\n",
    "\n",
    "    labels = np.array(labels, dtype=np.int32)\n",
    "    preds  = np.array(preds, dtype=np.int32)\n",
    "\n",
    "    pos_mask = (labels == 1)\n",
    "    neg_mask = (labels == 0)\n",
    "\n",
    "    if pos_mask.sum() > 0:\n",
    "        FRR = ((preds[pos_mask] == 0).sum() / pos_mask.sum())\n",
    "    else:\n",
    "        FRR = 0.0\n",
    "\n",
    "    if neg_mask.sum() > 0:\n",
    "        FAR = ((preds[neg_mask] == 1).sum() / neg_mask.sum())\n",
    "    else:\n",
    "        FAR = 0.0\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall (TPR): {rec:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    print(f\"FAR (False Accept Rate): {FAR:.4f}\")\n",
    "    print(f\"FRR (False Reject Rate): {FRR:.4f}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # ----- Load SNN distances -----\n",
    "    snn_data = np.load(SNN_NPZ)\n",
    "    val_dist   = snn_data[\"val_dist\"]\n",
    "    val_labels = snn_data[\"val_labels\"]\n",
    "    test_dist   = snn_data[\"test_dist\"]\n",
    "    test_labels = snn_data[\"test_labels\"]\n",
    "    print(\"Loaded SNN distances.\")\n",
    "    print(f\"SNN val pairs: {len(val_labels)}, test pairs: {len(test_labels)}\")\n",
    "\n",
    "    # ----- SNN METRICS -----\n",
    "    val_pred_snn  = (val_dist  <= BEST_THR_SNN).astype(np.int32)\n",
    "    test_pred_snn = (test_dist <= BEST_THR_SNN).astype(np.int32)\n",
    "\n",
    "    compute_binary_metrics(val_labels,  val_pred_snn,  name=\"SNN (VAL)\")\n",
    "    compute_binary_metrics(test_labels, test_pred_snn, name=\"SNN (TEST)\")\n",
    "\n",
    "    # ----- Load Elastic/Fusion scores -----\n",
    "    el_data = np.load(EL_FUS_NPZ)\n",
    "    elastic_val   = el_data[\"elastic_val\"]\n",
    "    labels_val_el = el_data[\"labels_val\"]\n",
    "    elastic_test  = el_data[\"elastic_test\"]\n",
    "    labels_test_el= el_data[\"labels_test\"]\n",
    "    fusion_val    = el_data[\"fusion_val\"]\n",
    "    fusion_test   = el_data[\"fusion_test\"]\n",
    "    best_thr_el   = float(el_data[\"best_thr_el\"])\n",
    "    best_thr_fus  = float(el_data[\"best_thr_fus\"])\n",
    "\n",
    "    print(\"\\nLoaded elastic/fusion scores.\")\n",
    "    print(f\"Elastic/Fusion val pairs: {len(labels_val_el)}, test pairs: {len(labels_test_el)}\")\n",
    "\n",
    "    # Note: labels_val_el / labels_test_el may be subsets (e.g., 50k) of full val/test\n",
    "\n",
    "    # ----- ELASTIC METRICS (on its subset) -----\n",
    "    val_pred_el  = (elastic_val  >= best_thr_el).astype(np.int32)\n",
    "    test_pred_el = (elastic_test >= best_thr_el).astype(np.int32)\n",
    "\n",
    "    compute_binary_metrics(labels_val_el,  val_pred_el,  name=\"ELASTIC (VAL)\")\n",
    "    compute_binary_metrics(labels_test_el, test_pred_el, name=\"ELASTIC (TEST)\")\n",
    "\n",
    "    # ----- FUSION METRICS (on same subset) -----\n",
    "    val_pred_fus  = (fusion_val  >= best_thr_fus).astype(np.int32)\n",
    "    test_pred_fus = (fusion_test >= best_thr_fus).astype(np.int32)\n",
    "\n",
    "    compute_binary_metrics(labels_val_el,  val_pred_fus,  name=\"FUSION (VAL)\")\n",
    "    compute_binary_metrics(labels_test_el, test_pred_fus, name=\"FUSION (TEST)\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cf39fd-48a7-4173-8acf-30f6b91626f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hf-env)",
   "language": "python",
   "name": "hf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
